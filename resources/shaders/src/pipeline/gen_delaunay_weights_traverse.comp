#version 460 core

#extension GL_KHR_shader_subgroup_clustered : require
#extension GL_KHR_shader_subgroup_shuffle   : require

#include <guard.glsl>
#include <math.glsl>

// Delaunay search tree; node data structure
struct Node { 
  vec3 minb; // Bounding volume maximum
  uint i;    // Begin index of underlying range
  vec3 maxb; // Bounding volume minimum
  uint n;    // Extent of underlying range
};

// Unit of work data assigned by the shader for the next task
struct WorkUnit {
  uint elem_i; // Index of the mesh tree node to be compared
  uint colr_i; // Index of the color tree node to be compared
};

// General layout rule declarations
layout(local_size_x = 256) in;
layout(std430)             buffer;
layout(std140)             uniform;

// Shader storage buffer declarations
layout(binding = 0) restrict readonly buffer b_elem { Node data[]; } elem_in;
layout(binding = 1) restrict readonly buffer b_colr { Node data[]; } colr_in;
layout(binding = 2) restrict coherent buffer b_flag { uint data[]; } flag_inout;
layout(binding = 3) restrict readonly buffer b_curr {
  uint     head;   // Atomic head count
  uint    _pad[3]; // 3x4by padding
  WorkUnit data[]; // Actual work data
} work_curr;
layout(binding = 4) restrict coherent buffer b_next {
  uint     head;   // Atomic head count
  uint    _pad[3]; // 3x4by padding
  WorkUnit data[]; // Actual work data
} work_next;
/* layout(binding = 5) restrict coherent buffer b_leaf {
  uint     head;   // Atomic head count
  uint    _pad[3]; // 3x4by padding
  WorkUnit data[]; // Actual work data
} work_leaf; */

// Uniform buffer declarations
layout(binding = 0) uniform b_unif {
  uint n_elem_lvls;
  uint n_colr_lvls;
  uint n_elems;
} unif_in;

// Subgroup helper declarations
const uint bvh_degr     = 8;
const uint bvh_degr_log = 3;
uint sg_invoc = gl_SubgroupInvocationID % bvh_degr;
uint sg_base  = gl_SubgroupInvocationID - sg_invoc;

// BVH traversal helper functions
const float bvh_degr_ln_div = 1.f / log(bvh_degr);
uint lvl_from_index(uint i) {
  return uint(log(float(i) * 7.f + 6.f) * bvh_degr_ln_div);
}

uint begin_from_lvl(uint lvl) {
  return (0x92492492 >> (31 - bvh_degr_log * lvl)) >> 3; 
}

// Test bbox intersection
bool intersect(in Node a, in Node b) {
  return all(greaterThan(a.maxb, b.minb)) && all(lessThan(a.minb, b.maxb));
}

void main() {
  const uint i = gl_GlobalInvocationID.x / bvh_degr;
  guard(i < work_curr.head);
  
  // A prior work-unit is shared among a 8-wide subgroup cluster
  WorkUnit unit_curr;
  if (sg_invoc == 0) {
    unit_curr = work_curr.data[i];  
  }
  unit_curr.elem_i = subgroupShuffle(unit_curr.elem_i, sg_base);
  unit_curr.colr_i = subgroupShuffle(unit_curr.colr_i, sg_base);

  // A current element is shared among a 8-wide subgroup cluster
  Node elem;
  if (sg_invoc == 0) {
    elem = elem_in.data[unit_curr.elem_i];
  }
  elem.minb = subgroupShuffle(elem.minb, sg_base);
  elem.i    = subgroupShuffle(elem.i,    sg_base);
  elem.maxb = subgroupShuffle(elem.maxb, sg_base);
  elem.n    = subgroupShuffle(elem.n,    sg_base);
  guard(elem.n != 0);

  // Descend along tree; 8-wide subdivision is split among a subgroup cluster
  WorkUnit unit_next = WorkUnit(unit_curr.elem_i, unit_curr.colr_i * bvh_degr + 1 + sg_invoc);
  Node colr = colr_in.data[unit_next.colr_i];
  guard(colr.n != 0);

  // This invocation remains active only for intersecting bounding boxes
  guard(intersect(elem, colr));
  
  // Determine current level, and test if a bottom node was reached
  uint next_lvl = lvl_from_index(unit_next.colr_i);
  if (next_lvl == unif_in.n_colr_lvls - 1) {
    // If a leaf was reached; flag elem nodes for comparison on this leaf
    uint next_lvl_offs = unit_next.colr_i - begin_from_lvl(next_lvl);
    uint flag_i = 2 * next_lvl_offs + unit_next.elem_i / 32;
    uint flag_v = 1u << (unit_next.elem_i % 32);
    atomicOr(flag_inout.data[flag_i], flag_v);
  } else {
    // Else, push newly subdivided workunit to the appropriate output queue
    work_next.data[atomicAdd(work_next.head, 1)] = unit_next;
  }
  
  /* // Push new, subdivided workunit to the appropriate output queue
  if (colr.n > gl_SubgroupSize) {
    work_next.data[atomicAdd(work_next.head, 1)] = unit_next;
  } else {
    work_leaf.data[atomicAdd(work_leaf.head, 1)] = unit_next;
  } */
}